"""
å¬å›ç‡99%+ & ç²¾ç¡®ç‡95%+ åŒä¼˜åŒ–æ–¹æ¡ˆ
å½“å‰: Recall=98.88%, Precision=92.66%
ç›®æ ‡: Recallâ‰¥99%, Precisionâ‰¥95%

ç­–ç•¥: é˜ˆå€¼ä¼˜åŒ– + TTA + åå¤„ç†
"""

import torch
import torch.nn.functional as F
import numpy as np
from sklearn.metrics import precision_recall_curve, f1_score, roc_curve, auc
import matplotlib.pyplot as plt

class ThresholdOptimizer:
    """é˜ˆå€¼ä¼˜åŒ–å™¨ - åœ¨å¬å›ç‡çº¦æŸä¸‹æœ€å¤§åŒ–ç²¾ç¡®ç‡"""
    
    @staticmethod
    def find_optimal_threshold_constrained(model, val_loader, device, 
                                          min_recall=0.99, plot=True):
        """
        åœ¨ä¿è¯æœ€ä½å¬å›ç‡çš„å‰æä¸‹ï¼Œæ‰¾åˆ°æœ€ä¼˜é˜ˆå€¼
        
        Args:
            min_recall: æœ€ä½å¬å›ç‡è¦æ±‚ï¼ˆé»˜è®¤99%ï¼‰
        
        Returns:
            optimal_threshold, metrics
        """
        print(f"\nå¯»æ‰¾æœ€ä¼˜é˜ˆå€¼ (å¬å›ç‡ â‰¥ {min_recall*100}%)")
        print("="*60)
        
        model.eval()
        all_probs = []
        all_labels = []
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹æ¦‚ç‡
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                outputs = model(images)
                probs = F.softmax(outputs, dim=1)
                
                all_probs.extend(probs[:, 1].cpu().numpy())
                all_labels.extend(labels.numpy())
        
        all_probs = np.array(all_probs)
        all_labels = np.array(all_labels)
        
        # è®¡ç®—PRæ›²çº¿
        precision, recall, thresholds = precision_recall_curve(all_labels, all_probs)
        
        # æ‰¾åˆ°æ»¡è¶³å¬å›ç‡è¦æ±‚çš„æœ€ä¼˜é˜ˆå€¼
        valid_indices = recall >= min_recall
        
        if not np.any(valid_indices):
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•è¾¾åˆ°{min_recall*100}%å¬å›ç‡")
            # é€€è€Œæ±‚å…¶æ¬¡ï¼Œæ‰¾åˆ°æœ€é«˜å¬å›ç‡
            best_idx = np.argmax(recall)
        else:
            # åœ¨æ»¡è¶³å¬å›ç‡çš„å‰æä¸‹ï¼Œé€‰æ‹©ç²¾ç¡®ç‡æœ€é«˜çš„
            valid_precision = precision[valid_indices]
            valid_recall = recall[valid_indices]
            valid_thresholds = thresholds[valid_indices[:-1]]  # thresholdsæ¯”precisionå°‘1
            
            best_idx = np.argmax(valid_precision)
            optimal_threshold = valid_thresholds[best_idx]
            optimal_precision = valid_precision[best_idx]
            optimal_recall = valid_recall[best_idx]
        
        # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„é˜ˆå€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if 'optimal_threshold' not in locals():
            optimal_threshold = 0.5
            preds = (all_probs > optimal_threshold).astype(int)
            from sklearn.metrics import precision_score, recall_score
            optimal_precision = precision_score(all_labels, preds)
            optimal_recall = recall_score(all_labels, preds)
        
        # è®¡ç®—F1
        preds = (all_probs > optimal_threshold).astype(int)
        optimal_f1 = f1_score(all_labels, preds)
        
        print(f"\nâœ… æœ€ä¼˜é˜ˆå€¼: {optimal_threshold:.4f}")
        print(f"   å¬å›ç‡: {optimal_recall:.4f} ({optimal_recall*100:.2f}%)")
        print(f"   ç²¾ç¡®ç‡: {optimal_precision:.4f} ({optimal_precision*100:.2f}%)")
        print(f"   F1åˆ†æ•°: {optimal_f1:.4f}")
        
        # å¯è§†åŒ–
        if plot:
            ThresholdOptimizer._plot_pr_curve(
                precision, recall, thresholds,
                optimal_threshold, optimal_precision, optimal_recall
            )
        
        metrics = {
            'threshold': optimal_threshold,
            'precision': optimal_precision,
            'recall': optimal_recall,
            'f1': optimal_f1
        }
        
        return optimal_threshold, metrics
    
    @staticmethod
    def _plot_pr_curve(precision, recall, thresholds, 
                      opt_threshold, opt_precision, opt_recall):
        """ç»˜åˆ¶PRæ›²çº¿"""
        plt.figure(figsize=(12, 5))
        
        # PRæ›²çº¿
        plt.subplot(1, 2, 1)
        plt.plot(recall, precision, 'b-', linewidth=2, label='PR Curve')
        plt.plot(opt_recall, opt_precision, 'r*', markersize=15, 
                label=f'Optimal (T={opt_threshold:.3f})')
        plt.xlabel('Recall', fontsize=12)
        plt.ylabel('Precision', fontsize=12)
        plt.title('Precision-Recall Curve', fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # é˜ˆå€¼ vs æŒ‡æ ‡
        plt.subplot(1, 2, 2)
        plt.plot(thresholds, precision[:-1], 'b-', label='Precision', linewidth=2)
        plt.plot(thresholds, recall[:-1], 'r-', label='Recall', linewidth=2)
        plt.axvline(opt_threshold, color='g', linestyle='--', 
                   label=f'Optimal T={opt_threshold:.3f}')
        plt.xlabel('Threshold', fontsize=12)
        plt.ylabel('Score', fontsize=12)
        plt.title('Threshold vs Metrics', fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('threshold_optimization.png', dpi=300)
        print("\nğŸ“Š é˜ˆå€¼ä¼˜åŒ–æ›²çº¿å·²ä¿å­˜: threshold_optimization.png")


class AdvancedTTA:
    """é«˜çº§TTAç­–ç•¥ - æå‡å¬å›ç‡åŒæ—¶ä¿æŒç²¾ç¡®ç‡"""
    
    def __init__(self, model, device):
        self.model = model
        self.device = device
    
    def predict_with_tta(self, image_tensor, threshold=0.5, 
                        num_augmentations=5, aggregation='soft_vote'):
        """
        TTAé¢„æµ‹
        
        Args:
            aggregation: 
                - 'soft_vote': æ¦‚ç‡å¹³å‡ï¼ˆæ¨èï¼Œå¹³è¡¡ï¼‰
                - 'hard_vote': å¤šæ•°æŠ•ç¥¨ï¼ˆé«˜å¬å›ï¼‰
                - 'conservative': ä¿å®ˆç­–ç•¥ï¼ˆé«˜ç²¾ç¡®ï¼‰
        """
        import torchvision.transforms.functional as TF
        
        self.model.eval()
        
        augmented_probs = []
        
        with torch.no_grad():
            # åŸå›¾
            img = image_tensor.unsqueeze(0).to(self.device)
            output = self.model(img)
            prob = F.softmax(output, dim=1)[0, 1].item()
            augmented_probs.append(prob)
            
            # TTAå¢å¼º
            for _ in range(num_augmentations - 1):
                # éšæœºå¢å¼º
                aug_img = image_tensor.clone()
                
                # æ°´å¹³ç¿»è½¬ (50%æ¦‚ç‡)
                if np.random.rand() > 0.5:
                    aug_img = TF.hflip(aug_img)
                
                # äº®åº¦è°ƒæ•´
                brightness_factor = np.random.uniform(0.9, 1.1)
                aug_img = TF.adjust_brightness(aug_img, brightness_factor)
                
                # å¯¹æ¯”åº¦è°ƒæ•´
                contrast_factor = np.random.uniform(0.9, 1.1)
                aug_img = TF.adjust_contrast(aug_img, contrast_factor)
                
                # æ¨ç†
                aug_img = aug_img.unsqueeze(0).to(self.device)
                output = self.model(aug_img)
                prob = F.softmax(output, dim=1)[0, 1].item()
                augmented_probs.append(prob)
        
        # èšåˆç­–ç•¥
        if aggregation == 'soft_vote':
            final_prob = np.mean(augmented_probs)
            is_overflow = final_prob > threshold
        
        elif aggregation == 'hard_vote':
            votes = [p > threshold for p in augmented_probs]
            is_overflow = sum(votes) > len(votes) / 2
            final_prob = np.mean(augmented_probs)
        
        elif aggregation == 'conservative':
            # ä¿å®ˆç­–ç•¥ï¼šè‡³å°‘75%çš„å¢å¼ºè®¤ä¸ºæ˜¯æº¢å‡º
            votes = [p > threshold for p in augmented_probs]
            is_overflow = sum(votes) >= len(votes) * 0.75
            final_prob = np.mean(augmented_probs)
        
        return is_overflow, final_prob, augmented_probs


class PostProcessor:
    """åå¤„ç†æ¨¡å— - æ—¶åºå¹³æ»‘ + è§„åˆ™è¿‡æ»¤"""
    
    def __init__(self, window_size=5, min_detections=2):
        """
        Args:
            window_size: æ—¶é—´çª—å£å¤§å°
            min_detections: çª—å£å†…æœ€å°‘æ£€æµ‹æ¬¡æ•°
        """
        self.window_size = window_size
        self.min_detections = min_detections
        self.history = []
        self.prob_history = []
    
    def update(self, is_overflow, overflow_prob):
        """
        æ›´æ–°æ£€æµ‹å†å²å¹¶è¿”å›æœ€ç»ˆåˆ¤æ–­
        
        Returns:
            final_alarm: æœ€ç»ˆæ˜¯å¦æŠ¥è­¦
            confidence: ç½®ä¿¡åº¦
        """
        self.history.append(int(is_overflow))
        self.prob_history.append(overflow_prob)
        
        # ä¿æŒçª—å£å¤§å°
        if len(self.history) > self.window_size:
            self.history.pop(0)
            self.prob_history.pop(0)
        
        # æ—¶åºå¹³æ»‘åˆ¤æ–­
        detection_count = sum(self.history)
        avg_prob = np.mean(self.prob_history)
        
        # è§¦å‘æ¡ä»¶
        final_alarm = detection_count >= self.min_detections
        
        # ç½®ä¿¡åº¦è®¡ç®—
        confidence = avg_prob if final_alarm else 1 - avg_prob
        
        return final_alarm, confidence
    
    def reset(self):
        """é‡ç½®å†å²"""
        self.history = []
        self.prob_history = []


# ============ å®Œæ•´è¯„ä¼°æµç¨‹ ============
def comprehensive_evaluation(model, val_loader, device):
    """
    ç»¼åˆè¯„ä¼° - æµ‹è¯•å¤šç§ä¼˜åŒ–ç»„åˆ
    """
    print("\n" + "="*60)
    print("ç»¼åˆè¯„ä¼° - æµ‹è¯•å¤šç§ä¼˜åŒ–ç­–ç•¥")
    print("="*60)
    
    # 1. åŸºçº¿ï¼ˆæ— ä¼˜åŒ–ï¼‰
    print("\nã€åŸºçº¿æµ‹è¯•ã€‘")
    baseline_metrics = evaluate_baseline(model, val_loader, device)
    
    # 2. é˜ˆå€¼ä¼˜åŒ–
    print("\nã€é˜ˆå€¼ä¼˜åŒ–ã€‘")
    optimal_threshold, threshold_metrics = ThresholdOptimizer.find_optimal_threshold_constrained(
        model, val_loader, device, min_recall=0.99, plot=True
    )
    
    # 3. TTAä¼˜åŒ–
    print("\nã€TTAä¼˜åŒ–ã€‘")
    tta_metrics = evaluate_with_tta(
        model, val_loader, device, threshold=optimal_threshold
    )
    
    # 4. æ—¶åºå¹³æ»‘
    print("\nã€æ—¶åºå¹³æ»‘ã€‘")
    temporal_metrics = evaluate_with_temporal_smoothing(
        model, val_loader, device, threshold=optimal_threshold
    )
    
    # æ±‡æ€»å¯¹æ¯”
    print("\n" + "="*60)
    print("æ€§èƒ½å¯¹æ¯”æ±‡æ€»")
    print("="*60)
    
    comparison = {
        'åŸºçº¿': baseline_metrics,
        'é˜ˆå€¼ä¼˜åŒ–': threshold_metrics,
        'TTAä¼˜åŒ–': tta_metrics,
        'æ—¶åºå¹³æ»‘': temporal_metrics
    }
    
    print(f"\n{'ç­–ç•¥':<12} {'å¬å›ç‡':<10} {'ç²¾ç¡®ç‡':<10} {'F1åˆ†æ•°':<10}")
    print("-" * 50)
    for name, metrics in comparison.items():
        print(f"{name:<12} {metrics['recall']:<10.4f} {metrics['precision']:<10.4f} {metrics['f1']:<10.4f}")
    
    return comparison


def evaluate_baseline(model, val_loader, device, threshold=0.5):
    """åŸºçº¿è¯„ä¼°"""
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            preds = (probs[:, 1] > threshold).cpu().numpy()
            
            all_preds.extend(preds)
            all_labels.extend(labels.numpy())
    
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    return {
        'precision': precision_score(all_labels, all_preds),
        'recall': recall_score(all_labels, all_preds),
        'f1': f1_score(all_labels, all_preds)
    }


def evaluate_with_tta(model, val_loader, device, threshold=0.5):
    """TTAè¯„ä¼°"""
    tta = AdvancedTTA(model, device)
    all_preds = []
    all_labels = []
    
    from tqdm import tqdm
    for images, labels in tqdm(val_loader, desc='TTAè¯„ä¼°'):
        for i in range(len(images)):
            img = images[i]
            is_overflow, _, _ = tta.predict_with_tta(
                img, threshold=threshold, 
                num_augmentations=5, 
                aggregation='soft_vote'
            )
            all_preds.append(int(is_overflow))
            all_labels.append(labels[i].item())
    
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    return {
        'precision': precision_score(all_labels, all_preds),
        'recall': recall_score(all_labels, all_preds),
        'f1': f1_score(all_labels, all_preds)
    }


def evaluate_with_temporal_smoothing(model, val_loader, device, threshold=0.5):
    """æ—¶åºå¹³æ»‘è¯„ä¼°ï¼ˆæ¨¡æ‹Ÿè§†é¢‘æµï¼‰"""
    model.eval()
    post_processor = PostProcessor(window_size=5, min_detections=2)
    
    all_final_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            
            for i in range(len(images)):
                overflow_prob = probs[i, 1].item()
                is_overflow = overflow_prob > threshold
                
                final_alarm, _ = post_processor.update(is_overflow, overflow_prob)
                
                all_final_preds.append(int(final_alarm))
                all_labels.append(labels[i].item())
    
    from sklearn.metrics import precision_score, recall_score, f1_score
    
    return {
        'precision': precision_score(all_labels, all_final_preds),
        'recall': recall_score(all_labels, all_final_preds),
        'f1': f1_score(all_labels, all_final_preds)
    }


# ============ å®é™…éƒ¨ç½²ç±» - é›†æˆæ‰€æœ‰ä¼˜åŒ– ============
class ProductionInference:
    """
    ç”Ÿäº§ç¯å¢ƒæ¨ç†ç±»
    é›†æˆ: é˜ˆå€¼ä¼˜åŒ– + TTA + æ—¶åºå¹³æ»‘
    """
    def __init__(self, model, device='cuda', config=None):
        """
        Args:
            config: {
                'threshold': 0.45,
                'use_tta': True,
                'tta_num': 5,
                'temporal_window': 5,
                'temporal_min_detections': 2
            }
        """
        self.model = model
        self.device = device
        
        # é»˜è®¤é…ç½®
        default_config = {
            'threshold': 0.45,
            'use_tta': True,
            'tta_num': 3,  # å®é™…éƒ¨ç½²å»ºè®®3-5æ¬¡
            'temporal_window': 5,
            'temporal_min_detections': 2
        }
        
        self.config = {**default_config, **(config or {})}
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.tta = AdvancedTTA(model, device) if self.config['use_tta'] else None
        self.post_processor = PostProcessor(
            window_size=self.config['temporal_window'],
            min_detections=self.config['temporal_min_detections']
        )
    
    def predict_frame(self, image_tensor):
        """
        å•å¸§é¢„æµ‹ï¼ˆè§†é¢‘æµåœºæ™¯ï¼‰
        
        Returns:
            {
                'instant_detection': bool,
                'final_alarm': bool,
                'confidence': float,
                'overflow_prob': float
            }
        """
        # TTAé¢„æµ‹
        if self.config['use_tta']:
            is_overflow, overflow_prob, _ = self.tta.predict_with_tta(
                image_tensor,
                threshold=self.config['threshold'],
                num_augmentations=self.config['tta_num']
            )
        else:
            # ç›´æ¥æ¨ç†
            self.model.eval()
            with torch.no_grad():
                img = image_tensor.unsqueeze(0).to(self.device)
                output = self.model(img)
                prob = F.softmax(output, dim=1)[0, 1].item()
                is_overflow = prob > self.config['threshold']
                overflow_prob = prob
        
        # æ—¶åºå¹³æ»‘
        final_alarm, confidence = self.post_processor.update(is_overflow, overflow_prob)
        
        return {
            'instant_detection': is_overflow,
            'final_alarm': final_alarm,
            'confidence': confidence,
            'overflow_prob': overflow_prob
        }
    
    def reset(self):
        """é‡ç½®æ—¶åºå†å²ï¼ˆæ–°è§†é¢‘å¼€å§‹æ—¶è°ƒç”¨ï¼‰"""
        self.post_processor.reset()
