"""
æ–¹æ¡ˆ4: é›†æˆæ‰€æœ‰ä¼˜åŒ–çš„å®Œæ•´è®­ç»ƒä»£ç 
åŸºäºä½ çš„æ¨¡å‹2ï¼Œæ·»åŠ ï¼š
1. Focal Loss
2. æ›´æ¿€è¿›çš„æ­£ç±»æƒé‡
3. æ•°æ®å¢å¼ºå¾®è°ƒ
4. æ··åˆç²¾åº¦è®­ç»ƒ
5. æ¢¯åº¦ç´¯ç§¯

é¢„æœŸ: Recall 97-98%, F1 97.5+%
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler
from efficientnet_pytorch import EfficientNet

# ============ æ ¸å¿ƒLosså‡½æ•° ============
class FocalLoss(nn.Module):
    def __init__(self, alpha=0.75, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_weight = (1 - pt) ** self.gamma
        
        alpha_weight = torch.where(
            targets == 1,
            torch.tensor(self.alpha).to(inputs.device),
            torch.tensor(1 - self.alpha).to(inputs.device)
        )
        
        loss = alpha_weight * focal_weight * ce_loss
        return loss.mean()


# ============ ä¼˜åŒ–çš„è®­ç»ƒå‡½æ•° ============
def train_epoch_optimized(train_loader, model, criterion, optimizer, 
                         epoch, args, scaler, accumulation_steps=2):
    """
    ä¼˜åŒ–çš„è®­ç»ƒepoch
    
    Args:
        accumulation_steps: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆæ¨¡æ‹Ÿæ›´å¤§batchï¼‰
    """
    model.train()
    running_loss = 0.0
    running_corrects = 0
    total_samples = 0
    
    optimizer.zero_grad()
    
    from tqdm import tqdm
    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')
    
    for i, (images, targets) in enumerate(pbar):
        images = images.cuda(args.gpu, non_blocking=True)
        targets = targets.cuda(args.gpu, non_blocking=True)
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        with autocast():
            outputs = model(images)
            loss = criterion(outputs, targets)
            loss = loss / accumulation_steps  # æ¢¯åº¦ç´¯ç§¯éœ€è¦å¹³å‡
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        
        # æ¢¯åº¦ç´¯ç§¯
        if (i + 1) % accumulation_steps == 0:
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
        
        # ç»Ÿè®¡
        _, preds = torch.max(outputs, 1)
        running_loss += loss.item() * images.size(0) * accumulation_steps
        running_corrects += torch.sum(preds == targets.data)
        total_samples += images.size(0)
        
        pbar.set_postfix({
            'loss': f'{running_loss / total_samples:.4f}',
            'acc': f'{running_corrects.double() / total_samples:.4f}'
        })
    
    epoch_loss = running_loss / total_samples
    epoch_acc = running_corrects.double() / total_samples
    
    return epoch_loss, epoch_acc.item()


# ============ ä¼˜åŒ–çš„éªŒè¯å‡½æ•° ============
def validate_optimized(val_loader, model, criterion, args, return_details=False):
    """ä¼˜åŒ–çš„éªŒè¯å‡½æ•°ï¼Œè¿”å›è¯¦ç»†æŒ‡æ ‡"""
    model.eval()
    
    all_preds = []
    all_probs = []
    all_labels = []
    running_loss = 0.0
    
    with torch.no_grad():
        for images, targets in val_loader:
            images = images.cuda(args.gpu, non_blocking=True)
            targets = targets.cuda(args.gpu, non_blocking=True)
            
            outputs = model(images)
            loss = criterion(outputs, targets)
            
            probs = F.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)
            
            running_loss += loss.item() * images.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_probs.extend(probs[:, 1].cpu().numpy())
            all_labels.extend(targets.cpu().numpy())
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    from sklearn.metrics import (classification_report, confusion_matrix,
                                 f1_score, precision_score, recall_score)
    
    epoch_loss = running_loss / len(val_loader.dataset)
    
    metrics = {
        'loss': epoch_loss,
        'f1': f1_score(all_labels, all_preds),
        'precision': precision_score(all_labels, all_preds),
        'recall': recall_score(all_labels, all_preds),
        'accuracy': sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)
    }
    
    if return_details:
        print("\n" + classification_report(all_labels, all_preds,
                                          target_names=['Normal', 'Overflow'],
                                          digits=4))
        cm = confusion_matrix(all_labels, all_preds)
        print(f"\nConfusion Matrix: TN={cm[0,0]}, FP={cm[0,1]}, FN={cm[1,0]}, TP={cm[1,1]}")
    
    return metrics, all_probs, all_labels


# ============ ä¸»è®­ç»ƒå‡½æ•°ï¼ˆæ›¿æ¢ä½ çš„main_workerï¼‰ ============
def main_worker_optimized(gpu, ngpus_per_node, args):
    """å®Œå…¨ä¼˜åŒ–çš„è®­ç»ƒæµç¨‹"""
    global best_acc1
    args.gpu = gpu
    
    # ========== æ¨¡å‹åˆå§‹åŒ– ==========
    if args.gpu is not None:
        print(f"Use GPU: {args.gpu} for training")
    
    model = EfficientNet.from_pretrained(
        args.arch,
        advprop=args.advprop,
        num_classes=2
    )
    
    if args.gpu is not None:
        torch.cuda.set_device(args.gpu)
        model = model.cuda(args.gpu)
    
    # ========== Losså‡½æ•°é€‰æ‹© ==========
    # æ–¹æ¡ˆA: Focal Lossï¼ˆæ¨èï¼‰
    criterion = FocalLoss(alpha=0.80, gamma=2.0).cuda(args.gpu)
    
    # æ–¹æ¡ˆB: åŠ æƒäº¤å‰ç†µï¼ˆå¤‡é€‰ï¼‰
    # class_counts = [54561, 27280]
    # weights = torch.tensor([0.25, 0.75]).cuda()  # æ›´æ¿€è¿›çš„æ­£ç±»æƒé‡
    # criterion = nn.CrossEntropyLoss(weight=weights).cuda(args.gpu)
    
    # ========== ä¼˜åŒ–å™¨é…ç½® ==========
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=3e-4,
        weight_decay=5e-4,
        betas=(0.9, 0.999)
    )
    
    # ========== å­¦ä¹ ç‡è°ƒåº¦å™¨ ==========
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=6,
        min_lr=1e-6,
        verbose=True
    )
    
    # ========== æ··åˆç²¾åº¦è®­ç»ƒ ==========
    scaler = GradScaler()
    
    # ========== æ•°æ®åŠ è½½ ==========
    import os
    from torchvision import transforms, datasets
    import PIL
    
    traindir = os.path.join(args.data, 'train')
    valdir = os.path.join(args.data, 'val')
    
    # ä¼˜åŒ–çš„æ•°æ®å¢å¼º
    normalize = transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1, 1, 1])
    image_size = EfficientNet.get_image_size(args.arch)
    
    train_transforms = transforms.Compose([
        transforms.RandomResizedCrop(
            image_size,
            scale=(0.7, 1.0),
            ratio=(0.85, 1.15),
            antialias=True
        ),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ColorJitter(
            brightness=0.2,
            contrast=0.2,
            saturation=0.15  # ç¨å¾®æé«˜
        ),
        transforms.ToTensor(),
        normalize,
        transforms.RandomErasing(
            p=0.25,  # ç¨å¾®æé«˜
            scale=(0.02, 0.15),
            ratio=(0.3, 3.3)
        )
    ])
    
    val_transforms = transforms.Compose([
        transforms.Resize(image_size, interpolation=PIL.Image.BICUBIC),
        transforms.CenterCrop(image_size),
        transforms.ToTensor(),
        normalize,
    ])
    
    train_dataset = datasets.ImageFolder(traindir, train_transforms)
    val_dataset = datasets.ImageFolder(valdir, val_transforms)
    
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.workers,
        pin_memory=True
    )
    
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.workers,
        pin_memory=True
    )
    
    # ========== è®­ç»ƒå¾ªç¯ ==========
    history = {
        'train_loss': [], 'val_loss': [],
        'train_acc': [], 'val_acc': [],
        'val_f1': [], 'val_recall': [], 'val_precision': []
    }
    
    best_f1 = 0.0
    patience_counter = 0
    max_patience = 15
    
    for epoch in range(args.epochs):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1}/{args.epochs}")
        print('='*60)
        
        # è®­ç»ƒ
        train_loss, train_acc = train_epoch_optimized(
            train_loader, model, criterion, optimizer,
            epoch, args, scaler, accumulation_steps=2
        )
        
        # éªŒè¯
        val_metrics, _, _ = validate_optimized(
            val_loader, model, criterion, args,
            return_details=(epoch % 5 == 0)  # æ¯5ä¸ªepochæ‰“å°è¯¦ç»†ä¿¡æ¯
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_metrics['loss'])
        
        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_metrics['loss'])
        history['val_acc'].append(val_metrics['accuracy'])
        history['val_f1'].append(val_metrics['f1'])
        history['val_recall'].append(val_metrics['recall'])
        history['val_precision'].append(val_metrics['precision'])
        
        # æ‰“å°æŒ‡æ ‡
        print(f"\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
        print(f"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['accuracy']:.4f}")
        print(f"Val F1: {val_metrics['f1']:.4f}, "
              f"Precision: {val_metrics['precision']:.4f}, "
              f"Recall: {val_metrics['recall']:.4f}")
        print(f"Current LR: {optimizer.param_groups[0]['lr']:.2e}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        is_best = val_metrics['f1'] > best_f1
        if is_best:
            best_f1 = val_metrics['f1']
            patience_counter = 0
            
            save_checkpoint({
                'epoch': epoch + 1,
                'state_dict': model.state_dict(),
                'best_f1': best_f1,
                'optimizer': optimizer.state_dict(),
                'metrics': val_metrics
            }, filename=f'model_best_f1_{best_f1:.4f}.pth.tar')
            
            print(f"âœ… New best F1: {best_f1:.4f}")
        else:
            patience_counter += 1
        
        # Early Stopping
        if patience_counter >= max_patience:
            print(f"\nâš ï¸ Early stopping at epoch {epoch+1}")
            break
    
    # å¯è§†åŒ–
    visualize_training_history(history)
    
    return model, history


# ============ å¯è§†åŒ–å‡½æ•° ============
def visualize_training_history(history):
    """å¯è§†åŒ–è®­ç»ƒå†å²"""
    import matplotlib.pyplot as plt
    
    epochs = range(1, len(history['train_loss']) + 1)
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Lossæ›²çº¿
    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    axes[0, 0].set_title('Loss Curve')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # Accuracyæ›²çº¿
    axes[0, 1].plot(epochs, history['train_acc'], 'b-', label='Train Acc')
    axes[0, 1].plot(epochs, history['val_acc'], 'r-', label='Val Acc')
    axes[0, 1].set_title('Accuracy Curve')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].legend()
    axes[0, 1].grid(True)
    
    # F1æ›²çº¿
    axes[1, 0].plot(epochs, history['val_f1'], 'g-', label='Val F1')
    axes[1, 0].set_title('F1 Score')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('F1')
    axes[1, 0].legend()
    axes[1, 0].grid(True)
    
    # Precision & Recall
    axes[1, 1].plot(epochs, history['val_precision'], 'b-', label='Precision')
    axes[1, 1].plot(epochs, history['val_recall'], 'r-', label='Recall')
    axes[1, 1].set_title('Precision & Recall')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Score')
    axes[1, 1].legend()
    axes[1, 1].grid(True)
    
    plt.tight_layout()
    plt.savefig('training_history_optimized.png', dpi=300)
    print("\nğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³ training_history_optimized.png")


# ============ æ£€æŸ¥ç‚¹ä¿å­˜ ============
def save_checkpoint(state, filename='checkpoint.pth.tar'):
    import os
    ckpt_dir = "/root/autodl-tmp/model_optimized"
    os.makedirs(ckpt_dir, exist_ok=True)
    
    ckpt_path = os.path.join(ckpt_dir, filename)
    torch.save(state, ckpt_path)
    print(f"âœ… Checkpoint saved: {ckpt_path}")
    
    # é¢å¤–ä¿å­˜çº¯æƒé‡
    if 'best' in filename:
        weight_path = os.path.join(ckpt_dir, 'best_model_weights.pth')
        torch.save(state['state_dict'], weight_path)
        print(f"ğŸ¯ Weights saved: {weight_path}")
